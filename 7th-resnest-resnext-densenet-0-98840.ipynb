{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ijYSEHmOf-62"
   },
   "source": [
    "## **树叶分类课程竞赛**\n",
    "- 首先要多谢Neko Kiku提供的baseline代码，思路非常清晰；\n",
    "- 本代码思想很简单，三个臭皮匠赛过诸葛亮，总共训练了3个优秀的模型（ResNeSt+ResNeXt+DenseNet）,最后进行集成，结果会更加鲁棒（公榜第12升到私榜第7也侧面反映了其鲁棒性）；\n",
    "- 代码是在本地计算机上跑的，由于Kaggle的运行时间有限制，无法分享运行完所有模型的结果，在这里我将我本地各个模型运行的结果附在了input文件夹里提供结果参考，以及方便走完代码整个流程；\n",
    "- 总结了图像分类任务的几个小技巧：\n",
    "1. 数据增强：特别是CutMix和预测时候对test样本进行TTA(Test Time Augmentation);\n",
    "2. 模型：可使用表现较好的预训练过的模型；\n",
    "3. 优化器：使用AdamW（对于含有L2正则项的优化，如weight decay），学习率采用cosine学习率CosineAnnealingLR;\n",
    "4. 交叉验证：使用K折交叉验证；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-28T04:06:50.384457Z",
     "iopub.status.busy": "2021-06-28T04:06:50.384037Z",
     "iopub.status.idle": "2021-06-28T04:06:58.736819Z",
     "shell.execute_reply": "2021-06-28T04:06:58.735628Z",
     "shell.execute_reply.started": "2021-06-28T04:06:50.384371Z"
    },
    "id": "BKct5uTcgFhY",
    "outputId": "8837faea-48bd-4796-bc1b-a76bcd2e9ddd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ttach\n",
      "  Downloading ttach-0.0.3-py3-none-any.whl (9.8 kB)\n",
      "Installing collected packages: ttach\n",
      "Successfully installed ttach-0.0.3\n"
     ]
    }
   ],
   "source": [
    "!pip install ttach\n",
    "# 安装TTA包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-28T04:07:12.669527Z",
     "iopub.status.busy": "2021-06-28T04:07:12.669137Z",
     "iopub.status.idle": "2021-06-28T04:07:21.625824Z",
     "shell.execute_reply": "2021-06-28T04:07:21.624993Z",
     "shell.execute_reply.started": "2021-06-28T04:07:12.669469Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/ildoonet/cutmix\n",
      "  Cloning https://github.com/ildoonet/cutmix to /tmp/pip-req-build-7718h9_e\n",
      "  Running command git clone -q https://github.com/ildoonet/cutmix /tmp/pip-req-build-7718h9_e\n",
      "Building wheels for collected packages: cutmix\n",
      "  Building wheel for cutmix (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for cutmix: filename=cutmix-0.1-py3-none-any.whl size=3600 sha256=75c4a802fdf68a8545b884bfa912c252e32bc31ab024fa2776be21703ea4bac5\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-mwpgkbm3/wheels/a9/81/a7/d3822499b14d97b1e2ef7e7538b70f15355607cfc7526f7cd5\n",
      "Successfully built cutmix\n",
      "Installing collected packages: cutmix\n",
      "Successfully installed cutmix-0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/ildoonet/cutmix \n",
    "# 安装CutMix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-28T04:07:32.767081Z",
     "iopub.status.busy": "2021-06-28T04:07:32.766716Z",
     "iopub.status.idle": "2021-06-28T04:07:42.356778Z",
     "shell.execute_reply": "2021-06-28T04:07:42.355538Z",
     "shell.execute_reply.started": "2021-06-28T04:07:32.767043Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: resnest in /home/lchalres/anaconda3/lib/python3.8/site-packages (0.0.6b20211214)\r\n",
      "Requirement already satisfied: fvcore in /home/lchalres/anaconda3/lib/python3.8/site-packages (from resnest) (0.1.5.post20211023)\r\n",
      "Requirement already satisfied: tqdm in /home/lchalres/anaconda3/lib/python3.8/site-packages (from resnest) (4.59.0)\r\n",
      "Requirement already satisfied: torch>=1.0.0 in /home/lchalres/anaconda3/lib/python3.8/site-packages (from resnest) (1.7.1)\r\n",
      "Requirement already satisfied: nose in /home/lchalres/anaconda3/lib/python3.8/site-packages (from resnest) (1.3.7)\r\n",
      "Requirement already satisfied: requests in /home/lchalres/anaconda3/lib/python3.8/site-packages (from resnest) (2.25.1)\r\n",
      "Requirement already satisfied: scipy in /home/lchalres/anaconda3/lib/python3.8/site-packages (from resnest) (1.6.2)\r\n",
      "Requirement already satisfied: Pillow in /home/lchalres/anaconda3/lib/python3.8/site-packages (from resnest) (8.3.2)\r\n",
      "Requirement already satisfied: iopath in /home/lchalres/anaconda3/lib/python3.8/site-packages (from resnest) (0.1.9)\r\n",
      "Requirement already satisfied: numpy in /home/lchalres/anaconda3/lib/python3.8/site-packages (from resnest) (1.21.4)\r\n",
      "Requirement already satisfied: typing_extensions in /home/lchalres/anaconda3/lib/python3.8/site-packages (from torch>=1.0.0->resnest) (3.7.4.3)\r\n",
      "Requirement already satisfied: termcolor>=1.1 in /home/lchalres/anaconda3/lib/python3.8/site-packages (from fvcore->resnest) (1.1.0)\r\n",
      "Requirement already satisfied: yacs>=0.1.6 in /home/lchalres/anaconda3/lib/python3.8/site-packages (from fvcore->resnest) (0.1.8)\r\n",
      "Requirement already satisfied: tabulate in /home/lchalres/anaconda3/lib/python3.8/site-packages (from fvcore->resnest) (0.8.9)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/lchalres/anaconda3/lib/python3.8/site-packages (from fvcore->resnest) (5.4.1)\r\n",
      "Requirement already satisfied: portalocker in /home/lchalres/anaconda3/lib/python3.8/site-packages (from iopath->resnest) (2.3.2)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/lchalres/anaconda3/lib/python3.8/site-packages (from requests->resnest) (1.26.4)\r\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/lchalres/anaconda3/lib/python3.8/site-packages (from requests->resnest) (4.0.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/lchalres/anaconda3/lib/python3.8/site-packages (from requests->resnest) (2020.12.5)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/lchalres/anaconda3/lib/python3.8/site-packages (from requests->resnest) (2.10)\r\n"
     ]
    }
   ],
   "source": [
    "# 安装ResNeSt模型包\n",
    "!pip install resnest --pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-28T04:07:53.208153Z",
     "iopub.status.busy": "2021-06-28T04:07:53.207773Z",
     "iopub.status.idle": "2021-06-28T04:07:55.565071Z",
     "shell.execute_reply": "2021-06-28T04:07:55.564094Z",
     "shell.execute_reply.started": "2021-06-28T04:07:53.208110Z"
    },
    "id": "5GrL5NlBgoal"
   },
   "outputs": [],
   "source": [
    "# 导入各种包\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import ttach as tta\n",
    "from resnest.torch import resnest50\n",
    "\n",
    "from cutmix.cutmix import CutMix\n",
    "from cutmix.utils import CutMixCrossEntropyLoss\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torchvision import transforms\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from sklearn.model_selection import KFold\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.models as models\n",
    "# This is for the progress bar.\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vLBrZv8rh6lE"
   },
   "source": [
    "### **整理数据集**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zuLp3H0lCpHr"
   },
   "source": [
    "### **数据读取与预处理**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-28T04:08:19.681387Z",
     "iopub.status.busy": "2021-06-28T04:08:19.681005Z",
     "iopub.status.idle": "2021-06-28T04:08:19.741419Z",
     "shell.execute_reply": "2021-06-28T04:08:19.740428Z",
     "shell.execute_reply.started": "2021-06-28T04:08:19.681353Z"
    },
    "id": "yIRBT3qRClaZ",
    "outputId": "cca948ce-4506-4b6b-e870-fc81b400924f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>images/0.jpg</td>\n",
       "      <td>maclura_pomifera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>images/1.jpg</td>\n",
       "      <td>maclura_pomifera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>images/2.jpg</td>\n",
       "      <td>maclura_pomifera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>images/3.jpg</td>\n",
       "      <td>maclura_pomifera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>images/4.jpg</td>\n",
       "      <td>maclura_pomifera</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          image             label\n",
       "0  images/0.jpg  maclura_pomifera\n",
       "1  images/1.jpg  maclura_pomifera\n",
       "2  images/2.jpg  maclura_pomifera\n",
       "3  images/3.jpg  maclura_pomifera\n",
       "4  images/4.jpg  maclura_pomifera"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 看看label文件长啥样\n",
    "labels_dataframe = pd.read_csv('./train.csv')\n",
    "labels_dataframe.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-28T04:08:21.869928Z",
     "iopub.status.busy": "2021-06-28T04:08:21.869472Z",
     "iopub.status.idle": "2021-06-28T04:08:21.882788Z",
     "shell.execute_reply": "2021-06-28T04:08:21.881448Z",
     "shell.execute_reply.started": "2021-06-28T04:08:21.869896Z"
    },
    "id": "cVaLR5JiC_-o",
    "outputId": "0a69cf0d-6467-428c-d819-d3c777bdb18c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['abies_concolor',\n",
       " 'abies_nordmanniana',\n",
       " 'acer_campestre',\n",
       " 'acer_ginnala',\n",
       " 'acer_griseum',\n",
       " 'acer_negundo',\n",
       " 'acer_palmatum',\n",
       " 'acer_pensylvanicum',\n",
       " 'acer_platanoides',\n",
       " 'acer_pseudoplatanus']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 把label文件排个序\n",
    "leaves_labels = sorted(list(set(labels_dataframe['label'])))\n",
    "n_classes = len(leaves_labels)\n",
    "print(n_classes)\n",
    "leaves_labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-28T04:08:24.053604Z",
     "iopub.status.busy": "2021-06-28T04:08:24.053191Z",
     "iopub.status.idle": "2021-06-28T04:08:24.066931Z",
     "shell.execute_reply": "2021-06-28T04:08:24.065858Z",
     "shell.execute_reply.started": "2021-06-28T04:08:24.053554Z"
    },
    "id": "tI2nHDzaDHfM",
    "outputId": "a8801bfc-1d59-4890-9b74-f24ddbc90eaa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abies_concolor': 0,\n",
       " 'abies_nordmanniana': 1,\n",
       " 'acer_campestre': 2,\n",
       " 'acer_ginnala': 3,\n",
       " 'acer_griseum': 4,\n",
       " 'acer_negundo': 5,\n",
       " 'acer_palmatum': 6,\n",
       " 'acer_pensylvanicum': 7,\n",
       " 'acer_platanoides': 8,\n",
       " 'acer_pseudoplatanus': 9,\n",
       " 'acer_rubrum': 10,\n",
       " 'acer_saccharinum': 11,\n",
       " 'acer_saccharum': 12,\n",
       " 'aesculus_flava': 13,\n",
       " 'aesculus_glabra': 14,\n",
       " 'aesculus_hippocastamon': 15,\n",
       " 'aesculus_pavi': 16,\n",
       " 'ailanthus_altissima': 17,\n",
       " 'albizia_julibrissin': 18,\n",
       " 'amelanchier_arborea': 19,\n",
       " 'amelanchier_canadensis': 20,\n",
       " 'amelanchier_laevis': 21,\n",
       " 'asimina_triloba': 22,\n",
       " 'betula_alleghaniensis': 23,\n",
       " 'betula_jacqemontii': 24,\n",
       " 'betula_lenta': 25,\n",
       " 'betula_nigra': 26,\n",
       " 'betula_populifolia': 27,\n",
       " 'broussonettia_papyrifera': 28,\n",
       " 'carpinus_betulus': 29,\n",
       " 'carpinus_caroliniana': 30,\n",
       " 'carya_cordiformis': 31,\n",
       " 'carya_glabra': 32,\n",
       " 'carya_ovata': 33,\n",
       " 'carya_tomentosa': 34,\n",
       " 'castanea_dentata': 35,\n",
       " 'catalpa_bignonioides': 36,\n",
       " 'catalpa_speciosa': 37,\n",
       " 'cedrus_atlantica': 38,\n",
       " 'cedrus_deodara': 39,\n",
       " 'cedrus_libani': 40,\n",
       " 'celtis_occidentalis': 41,\n",
       " 'celtis_tenuifolia': 42,\n",
       " 'cercidiphyllum_japonicum': 43,\n",
       " 'cercis_canadensis': 44,\n",
       " 'chamaecyparis_pisifera': 45,\n",
       " 'chamaecyparis_thyoides': 46,\n",
       " 'chionanthus_retusus': 47,\n",
       " 'chionanthus_virginicus': 48,\n",
       " 'cladrastis_lutea': 49,\n",
       " 'cornus_florida': 50,\n",
       " 'cornus_kousa': 51,\n",
       " 'cornus_mas': 52,\n",
       " 'crataegus_crus-galli': 53,\n",
       " 'crataegus_laevigata': 54,\n",
       " 'crataegus_phaenopyrum': 55,\n",
       " 'crataegus_pruinosa': 56,\n",
       " 'crataegus_viridis': 57,\n",
       " 'cryptomeria_japonica': 58,\n",
       " 'diospyros_virginiana': 59,\n",
       " 'eucommia_ulmoides': 60,\n",
       " 'evodia_daniellii': 61,\n",
       " 'fagus_grandifolia': 62,\n",
       " 'ficus_carica': 63,\n",
       " 'fraxinus_nigra': 64,\n",
       " 'fraxinus_pennsylvanica': 65,\n",
       " 'ginkgo_biloba': 66,\n",
       " 'gleditsia_triacanthos': 67,\n",
       " 'gymnocladus_dioicus': 68,\n",
       " 'halesia_tetraptera': 69,\n",
       " 'ilex_opaca': 70,\n",
       " 'juglans_cinerea': 71,\n",
       " 'juglans_nigra': 72,\n",
       " 'juniperus_virginiana': 73,\n",
       " 'koelreuteria_paniculata': 74,\n",
       " 'larix_decidua': 75,\n",
       " 'liquidambar_styraciflua': 76,\n",
       " 'liriodendron_tulipifera': 77,\n",
       " 'maclura_pomifera': 78,\n",
       " 'magnolia_acuminata': 79,\n",
       " 'magnolia_denudata': 80,\n",
       " 'magnolia_grandiflora': 81,\n",
       " 'magnolia_macrophylla': 82,\n",
       " 'magnolia_stellata': 83,\n",
       " 'magnolia_tripetala': 84,\n",
       " 'magnolia_virginiana': 85,\n",
       " 'malus_baccata': 86,\n",
       " 'malus_coronaria': 87,\n",
       " 'malus_floribunda': 88,\n",
       " 'malus_hupehensis': 89,\n",
       " 'malus_pumila': 90,\n",
       " 'metasequoia_glyptostroboides': 91,\n",
       " 'morus_alba': 92,\n",
       " 'morus_rubra': 93,\n",
       " 'nyssa_sylvatica': 94,\n",
       " 'ostrya_virginiana': 95,\n",
       " 'oxydendrum_arboreum': 96,\n",
       " 'paulownia_tomentosa': 97,\n",
       " 'phellodendron_amurense': 98,\n",
       " 'picea_abies': 99,\n",
       " 'picea_orientalis': 100,\n",
       " 'picea_pungens': 101,\n",
       " 'pinus_bungeana': 102,\n",
       " 'pinus_cembra': 103,\n",
       " 'pinus_densiflora': 104,\n",
       " 'pinus_echinata': 105,\n",
       " 'pinus_flexilis': 106,\n",
       " 'pinus_koraiensis': 107,\n",
       " 'pinus_nigra': 108,\n",
       " 'pinus_parviflora': 109,\n",
       " 'pinus_peucea': 110,\n",
       " 'pinus_pungens': 111,\n",
       " 'pinus_resinosa': 112,\n",
       " 'pinus_rigida': 113,\n",
       " 'pinus_strobus': 114,\n",
       " 'pinus_sylvestris': 115,\n",
       " 'pinus_taeda': 116,\n",
       " 'pinus_thunbergii': 117,\n",
       " 'pinus_virginiana': 118,\n",
       " 'pinus_wallichiana': 119,\n",
       " 'platanus_acerifolia': 120,\n",
       " 'platanus_occidentalis': 121,\n",
       " 'populus_deltoides': 122,\n",
       " 'populus_grandidentata': 123,\n",
       " 'populus_tremuloides': 124,\n",
       " 'prunus_pensylvanica': 125,\n",
       " 'prunus_sargentii': 126,\n",
       " 'prunus_serotina': 127,\n",
       " 'prunus_serrulata': 128,\n",
       " 'prunus_subhirtella': 129,\n",
       " 'prunus_virginiana': 130,\n",
       " 'prunus_yedoensis': 131,\n",
       " 'pseudolarix_amabilis': 132,\n",
       " 'ptelea_trifoliata': 133,\n",
       " 'pyrus_calleryana': 134,\n",
       " 'quercus_acutissima': 135,\n",
       " 'quercus_alba': 136,\n",
       " 'quercus_bicolor': 137,\n",
       " 'quercus_cerris': 138,\n",
       " 'quercus_coccinea': 139,\n",
       " 'quercus_imbricaria': 140,\n",
       " 'quercus_macrocarpa': 141,\n",
       " 'quercus_marilandica': 142,\n",
       " 'quercus_michauxii': 143,\n",
       " 'quercus_montana': 144,\n",
       " 'quercus_muehlenbergii': 145,\n",
       " 'quercus_nigra': 146,\n",
       " 'quercus_palustris': 147,\n",
       " 'quercus_phellos': 148,\n",
       " 'quercus_robur': 149,\n",
       " 'quercus_shumardii': 150,\n",
       " 'quercus_stellata': 151,\n",
       " 'quercus_velutina': 152,\n",
       " 'quercus_virginiana': 153,\n",
       " 'robinia_pseudo-acacia': 154,\n",
       " 'salix_babylonica': 155,\n",
       " 'salix_caroliniana': 156,\n",
       " 'salix_matsudana': 157,\n",
       " 'salix_nigra': 158,\n",
       " 'sassafras_albidum': 159,\n",
       " 'staphylea_trifolia': 160,\n",
       " 'stewartia_pseudocamellia': 161,\n",
       " 'styrax_japonica': 162,\n",
       " 'taxodium_distichum': 163,\n",
       " 'tilia_americana': 164,\n",
       " 'tilia_cordata': 165,\n",
       " 'tilia_europaea': 166,\n",
       " 'tilia_tomentosa': 167,\n",
       " 'tsuga_canadensis': 168,\n",
       " 'ulmus_americana': 169,\n",
       " 'ulmus_glabra': 170,\n",
       " 'ulmus_parvifolia': 171,\n",
       " 'ulmus_procera': 172,\n",
       " 'ulmus_pumila': 173,\n",
       " 'ulmus_rubra': 174,\n",
       " 'zelkova_serrata': 175}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 把label转成对应的数字\n",
    "class_to_num = dict(zip(leaves_labels, range(n_classes)))\n",
    "class_to_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-28T04:08:29.726580Z",
     "iopub.status.busy": "2021-06-28T04:08:29.726218Z",
     "iopub.status.idle": "2021-06-28T04:08:29.738603Z",
     "shell.execute_reply": "2021-06-28T04:08:29.737356Z",
     "shell.execute_reply.started": "2021-06-28T04:08:29.726549Z"
    },
    "id": "pL-bKsgqDKX4",
    "outputId": "96ff1167-3b0c-4c49-a510-60f40330497d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'abies_concolor',\n",
       " 1: 'abies_nordmanniana',\n",
       " 2: 'acer_campestre',\n",
       " 3: 'acer_ginnala',\n",
       " 4: 'acer_griseum',\n",
       " 5: 'acer_negundo',\n",
       " 6: 'acer_palmatum',\n",
       " 7: 'acer_pensylvanicum',\n",
       " 8: 'acer_platanoides',\n",
       " 9: 'acer_pseudoplatanus',\n",
       " 10: 'acer_rubrum',\n",
       " 11: 'acer_saccharinum',\n",
       " 12: 'acer_saccharum',\n",
       " 13: 'aesculus_flava',\n",
       " 14: 'aesculus_glabra',\n",
       " 15: 'aesculus_hippocastamon',\n",
       " 16: 'aesculus_pavi',\n",
       " 17: 'ailanthus_altissima',\n",
       " 18: 'albizia_julibrissin',\n",
       " 19: 'amelanchier_arborea',\n",
       " 20: 'amelanchier_canadensis',\n",
       " 21: 'amelanchier_laevis',\n",
       " 22: 'asimina_triloba',\n",
       " 23: 'betula_alleghaniensis',\n",
       " 24: 'betula_jacqemontii',\n",
       " 25: 'betula_lenta',\n",
       " 26: 'betula_nigra',\n",
       " 27: 'betula_populifolia',\n",
       " 28: 'broussonettia_papyrifera',\n",
       " 29: 'carpinus_betulus',\n",
       " 30: 'carpinus_caroliniana',\n",
       " 31: 'carya_cordiformis',\n",
       " 32: 'carya_glabra',\n",
       " 33: 'carya_ovata',\n",
       " 34: 'carya_tomentosa',\n",
       " 35: 'castanea_dentata',\n",
       " 36: 'catalpa_bignonioides',\n",
       " 37: 'catalpa_speciosa',\n",
       " 38: 'cedrus_atlantica',\n",
       " 39: 'cedrus_deodara',\n",
       " 40: 'cedrus_libani',\n",
       " 41: 'celtis_occidentalis',\n",
       " 42: 'celtis_tenuifolia',\n",
       " 43: 'cercidiphyllum_japonicum',\n",
       " 44: 'cercis_canadensis',\n",
       " 45: 'chamaecyparis_pisifera',\n",
       " 46: 'chamaecyparis_thyoides',\n",
       " 47: 'chionanthus_retusus',\n",
       " 48: 'chionanthus_virginicus',\n",
       " 49: 'cladrastis_lutea',\n",
       " 50: 'cornus_florida',\n",
       " 51: 'cornus_kousa',\n",
       " 52: 'cornus_mas',\n",
       " 53: 'crataegus_crus-galli',\n",
       " 54: 'crataegus_laevigata',\n",
       " 55: 'crataegus_phaenopyrum',\n",
       " 56: 'crataegus_pruinosa',\n",
       " 57: 'crataegus_viridis',\n",
       " 58: 'cryptomeria_japonica',\n",
       " 59: 'diospyros_virginiana',\n",
       " 60: 'eucommia_ulmoides',\n",
       " 61: 'evodia_daniellii',\n",
       " 62: 'fagus_grandifolia',\n",
       " 63: 'ficus_carica',\n",
       " 64: 'fraxinus_nigra',\n",
       " 65: 'fraxinus_pennsylvanica',\n",
       " 66: 'ginkgo_biloba',\n",
       " 67: 'gleditsia_triacanthos',\n",
       " 68: 'gymnocladus_dioicus',\n",
       " 69: 'halesia_tetraptera',\n",
       " 70: 'ilex_opaca',\n",
       " 71: 'juglans_cinerea',\n",
       " 72: 'juglans_nigra',\n",
       " 73: 'juniperus_virginiana',\n",
       " 74: 'koelreuteria_paniculata',\n",
       " 75: 'larix_decidua',\n",
       " 76: 'liquidambar_styraciflua',\n",
       " 77: 'liriodendron_tulipifera',\n",
       " 78: 'maclura_pomifera',\n",
       " 79: 'magnolia_acuminata',\n",
       " 80: 'magnolia_denudata',\n",
       " 81: 'magnolia_grandiflora',\n",
       " 82: 'magnolia_macrophylla',\n",
       " 83: 'magnolia_stellata',\n",
       " 84: 'magnolia_tripetala',\n",
       " 85: 'magnolia_virginiana',\n",
       " 86: 'malus_baccata',\n",
       " 87: 'malus_coronaria',\n",
       " 88: 'malus_floribunda',\n",
       " 89: 'malus_hupehensis',\n",
       " 90: 'malus_pumila',\n",
       " 91: 'metasequoia_glyptostroboides',\n",
       " 92: 'morus_alba',\n",
       " 93: 'morus_rubra',\n",
       " 94: 'nyssa_sylvatica',\n",
       " 95: 'ostrya_virginiana',\n",
       " 96: 'oxydendrum_arboreum',\n",
       " 97: 'paulownia_tomentosa',\n",
       " 98: 'phellodendron_amurense',\n",
       " 99: 'picea_abies',\n",
       " 100: 'picea_orientalis',\n",
       " 101: 'picea_pungens',\n",
       " 102: 'pinus_bungeana',\n",
       " 103: 'pinus_cembra',\n",
       " 104: 'pinus_densiflora',\n",
       " 105: 'pinus_echinata',\n",
       " 106: 'pinus_flexilis',\n",
       " 107: 'pinus_koraiensis',\n",
       " 108: 'pinus_nigra',\n",
       " 109: 'pinus_parviflora',\n",
       " 110: 'pinus_peucea',\n",
       " 111: 'pinus_pungens',\n",
       " 112: 'pinus_resinosa',\n",
       " 113: 'pinus_rigida',\n",
       " 114: 'pinus_strobus',\n",
       " 115: 'pinus_sylvestris',\n",
       " 116: 'pinus_taeda',\n",
       " 117: 'pinus_thunbergii',\n",
       " 118: 'pinus_virginiana',\n",
       " 119: 'pinus_wallichiana',\n",
       " 120: 'platanus_acerifolia',\n",
       " 121: 'platanus_occidentalis',\n",
       " 122: 'populus_deltoides',\n",
       " 123: 'populus_grandidentata',\n",
       " 124: 'populus_tremuloides',\n",
       " 125: 'prunus_pensylvanica',\n",
       " 126: 'prunus_sargentii',\n",
       " 127: 'prunus_serotina',\n",
       " 128: 'prunus_serrulata',\n",
       " 129: 'prunus_subhirtella',\n",
       " 130: 'prunus_virginiana',\n",
       " 131: 'prunus_yedoensis',\n",
       " 132: 'pseudolarix_amabilis',\n",
       " 133: 'ptelea_trifoliata',\n",
       " 134: 'pyrus_calleryana',\n",
       " 135: 'quercus_acutissima',\n",
       " 136: 'quercus_alba',\n",
       " 137: 'quercus_bicolor',\n",
       " 138: 'quercus_cerris',\n",
       " 139: 'quercus_coccinea',\n",
       " 140: 'quercus_imbricaria',\n",
       " 141: 'quercus_macrocarpa',\n",
       " 142: 'quercus_marilandica',\n",
       " 143: 'quercus_michauxii',\n",
       " 144: 'quercus_montana',\n",
       " 145: 'quercus_muehlenbergii',\n",
       " 146: 'quercus_nigra',\n",
       " 147: 'quercus_palustris',\n",
       " 148: 'quercus_phellos',\n",
       " 149: 'quercus_robur',\n",
       " 150: 'quercus_shumardii',\n",
       " 151: 'quercus_stellata',\n",
       " 152: 'quercus_velutina',\n",
       " 153: 'quercus_virginiana',\n",
       " 154: 'robinia_pseudo-acacia',\n",
       " 155: 'salix_babylonica',\n",
       " 156: 'salix_caroliniana',\n",
       " 157: 'salix_matsudana',\n",
       " 158: 'salix_nigra',\n",
       " 159: 'sassafras_albidum',\n",
       " 160: 'staphylea_trifolia',\n",
       " 161: 'stewartia_pseudocamellia',\n",
       " 162: 'styrax_japonica',\n",
       " 163: 'taxodium_distichum',\n",
       " 164: 'tilia_americana',\n",
       " 165: 'tilia_cordata',\n",
       " 166: 'tilia_europaea',\n",
       " 167: 'tilia_tomentosa',\n",
       " 168: 'tsuga_canadensis',\n",
       " 169: 'ulmus_americana',\n",
       " 170: 'ulmus_glabra',\n",
       " 171: 'ulmus_parvifolia',\n",
       " 172: 'ulmus_procera',\n",
       " 173: 'ulmus_pumila',\n",
       " 174: 'ulmus_rubra',\n",
       " 175: 'zelkova_serrata'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 再转换回来，方便最后预测的时候使用\n",
    "num_to_class = {v : k for k, v in class_to_num.items()}\n",
    "num_to_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-28T04:08:34.030629Z",
     "iopub.status.busy": "2021-06-28T04:08:34.030255Z",
     "iopub.status.idle": "2021-06-28T04:08:34.042265Z",
     "shell.execute_reply": "2021-06-28T04:08:34.041011Z",
     "shell.execute_reply.started": "2021-06-28T04:08:34.030598Z"
    },
    "id": "dyYerVWThdSX"
   },
   "outputs": [],
   "source": [
    "# 继承pytorch的dataset，创建自己的\n",
    "class TrainValidData(Dataset):\n",
    "    def __init__(self, csv_path, file_path, resize_height=224, resize_width=224, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_path (string): csv 文件路径\n",
    "            img_path (string): 图像文件所在路径\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        # 需要调整后的照片尺寸，我这里每张图片的大小尺寸不一致#\n",
    "        self.resize_height = resize_height\n",
    "        self.resize_width = resize_width\n",
    "\n",
    "        self.file_path = file_path\n",
    "        self.to_tensor = transforms.ToTensor() #将数据转换成tensor形式\n",
    "        self.transform = transform\n",
    "\n",
    "        # 读取 csv 文件\n",
    "        # 利用pandas读取csv文件\n",
    "        self.data_info = pd.read_csv(csv_path, header=None)  #header=None是去掉表头部分\n",
    "        # 文件第一列包含图像文件名称\n",
    "        self.image_arr = np.asarray(self.data_info.iloc[1:,0]) #self.data_info.iloc[1:,0]表示读取第一列，从第二行开始一直读取到最后一行\n",
    "        # 第二列是图像的 label\n",
    "        self.label_arr = np.asarray(self.data_info.iloc[1:,1])\n",
    "        # 计算 length\n",
    "        self.data_len = len(self.data_info.index) - 1\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # 从 image_arr中得到索引对应的文件名\n",
    "        single_image_name = self.image_arr[index]\n",
    "\n",
    "        # 读取图像文件\n",
    "        img_as_img = Image.open(self.file_path + single_image_name)\n",
    "        \n",
    "        #如果需要将RGB三通道的图片转换成灰度图片可参考下面两行\n",
    "        # if img_as_img.mode != 'L':\n",
    "        #     img_as_img = img_as_img.convert('L')\n",
    "        \n",
    "        #设置好需要转换的变量，还可以包括一系列的nomarlize等等操作\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "        img_as_img = transform(img_as_img)\n",
    "\n",
    "        # 得到图像的 label\n",
    "        label = self.label_arr[index]\n",
    "        number_label = class_to_num[label]\n",
    "\n",
    "        return (img_as_img, number_label)  #返回每一个index对应的图片数据和对应的label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-28T04:08:59.984047Z",
     "iopub.status.busy": "2021-06-28T04:08:59.983643Z",
     "iopub.status.idle": "2021-06-28T04:08:59.994125Z",
     "shell.execute_reply": "2021-06-28T04:08:59.992907Z",
     "shell.execute_reply.started": "2021-06-28T04:08:59.984010Z"
    },
    "id": "ckc_0XmovBHT"
   },
   "outputs": [],
   "source": [
    "# 继承pytorch的dataset，创建自己的\n",
    "class TestData(Dataset):\n",
    "    def __init__(self, csv_path, file_path, resize_height=224, resize_width=224, transform = None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_path (string): csv 文件路径\n",
    "            img_path (string): 图像文件所在路径\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        # 需要调整后的照片尺寸，我这里每张图片的大小尺寸不一致#\n",
    "        self.resize_height = resize_height\n",
    "        self.resize_width = resize_width\n",
    "\n",
    "        self.file_path = file_path\n",
    "        self.transform = transform\n",
    "        self.to_tensor = transforms.ToTensor() #将数据转换成tensor形式\n",
    "\n",
    "        # 读取 csv 文件\n",
    "        # 利用pandas读取csv文件\n",
    "        self.data_info = pd.read_csv(csv_path, header=None)  #header=None是去掉表头部分\n",
    "        # 文件第一列包含图像文件名称\n",
    "        self.image_arr = np.asarray(self.data_info.iloc[1:,0]) #self.data_info.iloc[1:,0]表示读取第一列，从第二行开始一直读取到最后一行\n",
    "        # 计算 length\n",
    "        self.data_len = len(self.data_info.index) - 1\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # 从 image_arr中得到索引对应的文件名\n",
    "        single_image_name = self.image_arr[index]\n",
    "\n",
    "        # 读取图像文件\n",
    "        img_as_img = Image.open(self.file_path + single_image_name)\n",
    "        \n",
    "        #如果需要将RGB三通道的图片转换成灰度图片可参考下面两行\n",
    "        # if img_as_img.mode != 'L':\n",
    "        #     img_as_img = img_as_img.convert('L')\n",
    "        \n",
    "        #设置好需要转换的变量，还可以包括一系列的nomarlize等等操作\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "        img_as_img = transform(img_as_img)\n",
    "\n",
    "\n",
    "        return img_as_img\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-28T04:09:03.944223Z",
     "iopub.status.busy": "2021-06-28T04:09:03.943839Z",
     "iopub.status.idle": "2021-06-28T04:09:03.951579Z",
     "shell.execute_reply": "2021-06-28T04:09:03.950354Z",
     "shell.execute_reply.started": "2021-06-28T04:09:03.944192Z"
    },
    "id": "8W9yJbmsVuN_"
   },
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    # 随机裁剪图像，所得图像为原始面积的0.08到1之间，高宽比在3/4和4/3之间。\n",
    "    # 然后，缩放图像以创建224 x 224的新图像\n",
    "    transforms.RandomResizedCrop(224, scale=(0.08, 1.0), ratio=(3.0 / 4.0, 4.0 / 3.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    # 随机更改亮度，对比度和饱和度\n",
    "    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4),\n",
    "    # 添加随机噪声\n",
    "    transforms.ToTensor(),\n",
    "    # 标准化图像的每个通道\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])])\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    # 从图像中心裁切224x224大小的图片\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-28T04:09:11.630611Z",
     "iopub.status.busy": "2021-06-28T04:09:11.630227Z",
     "iopub.status.idle": "2021-06-28T04:09:11.682046Z",
     "shell.execute_reply": "2021-06-28T04:09:11.681184Z",
     "shell.execute_reply.started": "2021-06-28T04:09:11.630579Z"
    },
    "id": "-y969Ozht3gI",
    "outputId": "36224e70-3481-484f-f909-73d1c72bbca4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      0                        1\n",
      "0                 image                    label\n",
      "1          images/0.jpg         maclura_pomifera\n",
      "2          images/1.jpg         maclura_pomifera\n",
      "3          images/2.jpg         maclura_pomifera\n",
      "4          images/3.jpg         maclura_pomifera\n",
      "...                 ...                      ...\n",
      "18349  images/18348.jpg          aesculus_glabra\n",
      "18350  images/18349.jpg  liquidambar_styraciflua\n",
      "18351  images/18350.jpg            cedrus_libani\n",
      "18352  images/18351.jpg      prunus_pensylvanica\n",
      "18353  images/18352.jpg          quercus_montana\n",
      "\n",
      "[18354 rows x 2 columns]\n",
      "                     0\n",
      "0                image\n",
      "1     images/18353.jpg\n",
      "2     images/18354.jpg\n",
      "3     images/18355.jpg\n",
      "4     images/18356.jpg\n",
      "...                ...\n",
      "8796  images/27148.jpg\n",
      "8797  images/27149.jpg\n",
      "8798  images/27150.jpg\n",
      "8799  images/27151.jpg\n",
      "8800  images/27152.jpg\n",
      "\n",
      "[8801 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "train_val_path = 'train.csv'\n",
    "test_path = 'test.csv'\n",
    "# csv文件中已经images的路径了，因此这里只到上一级目录\n",
    "img_path = ''\n",
    "\n",
    "train_val_dataset = TrainValidData(train_val_path, img_path)\n",
    "test_dataset = TestData(test_path, img_path, transform = val_test_transform)\n",
    "print(train_val_dataset.data_info)\n",
    "print(test_dataset.data_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **基于ResNeSt模型部分**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nk1vuWbh-7Ry"
   },
   "source": [
    "### **ResNeSt模型**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-28T04:09:15.903169Z",
     "iopub.status.busy": "2021-06-28T04:09:15.902682Z",
     "iopub.status.idle": "2021-06-28T04:09:15.909184Z",
     "shell.execute_reply": "2021-06-28T04:09:15.907947Z",
     "shell.execute_reply.started": "2021-06-28T04:09:15.903138Z"
    },
    "id": "QflrcSQF-ouz"
   },
   "outputs": [],
   "source": [
    "# 是否要冻住模型的前面一些层\n",
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        model = model\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "# ResNeSt模型\n",
    "def resnest_model(num_classes, feature_extract = False):\n",
    "    model_ft = resnest50(pretrained=True)\n",
    "    set_parameter_requires_grad(model_ft, feature_extract)\n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "    model_ft.fc = nn.Sequential(nn.Linear(num_ftrs, num_classes))\n",
    "\n",
    "    return model_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-28T04:03:23.674675Z",
     "iopub.status.idle": "2021-06-28T04:03:23.675083Z"
    },
    "id": "AoIkdlqo_ZKD",
    "outputId": "123aeca7-95b4-4386-88c6-76d8df096d59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# 看一下是在cpu还是GPU上\n",
    "def get_device():\n",
    "    return 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "device = get_device()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-28T04:03:23.675869Z",
     "iopub.status.idle": "2021-06-28T04:03:23.676312Z"
    },
    "id": "jb4HXVVBmzEe",
    "outputId": "f9e81580-f790-4607-cb30-3b05f4be84c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Dec 15 16:37:21 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 430.50       Driver Version: 430.50       CUDA Version: 10.1     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Quadro P1000        Off  | 00000000:01:00.0 Off |                  N/A |\r\n",
      "| 34%   44C    P0    N/A /  N/A |   4026MiB /  4040MiB |      1%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0      1768      G   /usr/lib/xorg/Xorg                           300MiB |\r\n",
      "|    0      1942      G   /usr/bin/gnome-shell                         133MiB |\r\n",
      "|    0      2537      G   ...quest-channel-token=1908319924670290939    94MiB |\r\n",
      "|    0      2849      C   /home/lchalres/anaconda3/bin/python         1159MiB |\r\n",
      "|    0      5283      C   /home/lchalres/anaconda3/bin/python         2335MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-28T04:12:31.359401Z",
     "iopub.status.busy": "2021-06-28T04:12:31.358819Z",
     "iopub.status.idle": "2021-06-28T04:12:31.369570Z",
     "shell.execute_reply": "2021-06-28T04:12:31.368525Z",
     "shell.execute_reply.started": "2021-06-28T04:12:31.359363Z"
    },
    "id": "hkkwMZyKuuKd"
   },
   "outputs": [],
   "source": [
    "# Configuration options\n",
    "k_folds = 5\n",
    "num_epochs = 30\n",
    "learning_rate = 1e-4\n",
    "weight_decay = 1e-3\n",
    "train_loss_function = CutMixCrossEntropyLoss(True)\n",
    "valid_loss_function = nn.CrossEntropyLoss()\n",
    "# For fold results\n",
    "results = {}\n",
    "\n",
    "# Set fixed random number seed\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=k_folds, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TobMADIKCilB"
   },
   "source": [
    "### **训练**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-28T04:03:23.678839Z",
     "iopub.status.idle": "2021-06-28T04:03:23.679278Z"
    },
    "id": "lwVkf8zm8z1W",
    "outputId": "629b6575-6f85-4da3-a34d-b580b0172e1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "FOLD 0\n",
      "--------------------------------------\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 3.95 GiB total capacity; 1.76 GiB already allocated; 9.50 MiB free; 1.79 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-44ba8e373492>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'empty_cache'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    610\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m     def register_backward_hook(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    608\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mconvert_to_format\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 3.95 GiB total capacity; 1.76 GiB already allocated; 9.50 MiB free; 1.79 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "# Start print\n",
    "print('--------------------------------------')\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "for fold, (train_ids,valid_ids) in enumerate(kfold.split(train_val_dataset)):\n",
    "\n",
    "  # Print\n",
    "  print(f'FOLD {fold}')\n",
    "  print('--------------------------------------')\n",
    "\n",
    "  # Sample elements randomly from a given list of ids, no replacement.\n",
    "  train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "  valid_subsampler = torch.utils.data.SubsetRandomSampler(valid_ids)\n",
    "\n",
    "  # Define data loaders for training and testing data in this fold\n",
    "  trainloader = torch.utils.data.DataLoader(\n",
    "                      CutMix(TrainValidData(train_val_path, img_path, transform = train_transform), num_class=176, beta=1.0, prob=0.5, num_mix=2), \n",
    "                      batch_size=8, sampler=train_subsampler, num_workers=0)\n",
    "  validloader = torch.utils.data.DataLoader(\n",
    "                      TrainValidData(train_val_path, img_path, transform = val_test_transform),\n",
    "                      batch_size=8, sampler=valid_subsampler, num_workers=0)\n",
    "  \n",
    "  # Initialize a model and put it on the device specified.\n",
    "  model = resnest_model(176)\n",
    "  if hasattr(torch.cuda, 'empty_cache'):\n",
    "        torch.cuda.empty_cache()  \n",
    "  model = model.to(device)\n",
    "  model.device = device\n",
    "  \n",
    "  # Initialize optimizer\n",
    "  optimizer = torch.optim.AdamW(model.parameters(),lr=learning_rate,weight_decay= weight_decay)\n",
    "  scheduler = CosineAnnealingLR(optimizer,T_max=10)\n",
    "\n",
    "  # Run the training loop for defined number of epochs\n",
    "  for epoch in range(0,num_epochs):\n",
    "    model.train()\n",
    "    # Print epoch\n",
    "    print(f'Starting epoch {epoch+1}')\n",
    "    # These are used to record information in training\n",
    "    train_losses = []\n",
    "    train_accs = []\n",
    "    # Iterate the training set by batches\n",
    "    for batch in tqdm(trainloader):\n",
    "      # Move images and labels to GPU\n",
    "      imgs, labels = batch\n",
    "      \n",
    "      imgs = imgs.to(device)\n",
    "      labels = labels.to(device)\n",
    "      # Forward the data\n",
    "      logits = model(imgs)\n",
    "      # Calculate loss\n",
    "      loss = train_loss_function(logits,labels)\n",
    "      # Clear gradients in previous step\n",
    "      optimizer.zero_grad()\n",
    "      # Compute gradients for parameters\n",
    "      loss.backward()\n",
    "      # Update the parameters with computed gradients\n",
    "      optimizer.step()\n",
    "      # Compute the accuracy for current batch.\n",
    "      # acc = (logits.argmax(dim=-1) == labels).float().mean()\n",
    "      # Record the loss and accuracy.\n",
    "      train_losses.append(loss.item())\n",
    "      # train_accs.append(acc)\n",
    "    print(\"第%d个epoch的学习率：%f\" % (epoch+1,optimizer.param_groups[0]['lr']))\n",
    "    scheduler.step()\n",
    "    # The average loss and accuracy of the training set is the average of the recorded values.\n",
    "    train_loss = np.sum(train_losses) / len(train_losses)\n",
    "    # train_acc = np.sum(train_accs) / len(train_accs)\n",
    "    # Print the information.\n",
    "    # print(f\"[ Train | {epoch + 1:03d}/{num_epochs:03d} ] loss = {train_loss:.5f}, acc = {train_acc:.5f}\")\n",
    "    print(f\"[ Train | {epoch + 1:03d}/{num_epochs:03d} ] loss = {train_loss:.5f}\")\n",
    "\n",
    "  # Train process (all epochs) is complete\n",
    "  print('Training process has finished. Saving trained model.')\n",
    "  print('Starting validation')\n",
    "\n",
    "  # Saving the model\n",
    "  print('saving model with loss {:.3f}'.format(train_loss))\n",
    "  save_path = f'./model-fold-{fold}.pth'\n",
    "  torch.save(model.state_dict(),save_path)\n",
    "  # Start Validation\n",
    "  model.eval()\n",
    "  valid_losses = []\n",
    "  valid_accs = []\n",
    "  with torch.no_grad():\n",
    "    for batch in tqdm(validloader):\n",
    "      imgs, labels = batch\n",
    "      # No gradient in validation\n",
    "      logits = model(imgs.to(device))\n",
    "      loss = valid_loss_function(logits,labels.to(device))\n",
    "      acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n",
    "      # Record loss and accuracy\n",
    "      valid_losses.append(loss.item())        \n",
    "      valid_accs.append(acc)\n",
    "    # The average loss and accuracy\n",
    "    valid_loss = np.sum(valid_losses)/len(valid_losses)\n",
    "    valid_acc = np.sum(valid_accs)/len(valid_accs)\n",
    "    print(f\"[ Valid | {epoch + 1:03d}/{num_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}\")\n",
    "    print('Accuracy for fold %d: %d' % (fold, valid_acc))\n",
    "    print('--------------------------------------')\n",
    "    results[fold] = valid_acc\n",
    "# Print fold results\n",
    "print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n",
    "print('--------------------------------')\n",
    "total_summation = 0.0\n",
    "for key, value in results.items():\n",
    "  print(f'Fold {key}: {value} ')\n",
    "  total_summation += value\n",
    "print(f'Average: {total_summation/len(results.items())} ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4eQyBuNbOHzy"
   },
   "source": [
    "### **预测**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-28T04:12:37.026763Z",
     "iopub.status.busy": "2021-06-28T04:12:37.026383Z",
     "iopub.status.idle": "2021-06-28T04:12:37.045990Z",
     "shell.execute_reply": "2021-06-28T04:12:37.044640Z",
     "shell.execute_reply.started": "2021-06-28T04:12:37.026724Z"
    },
    "id": "aoUIdMxGXNk-"
   },
   "outputs": [],
   "source": [
    "testloader = torch.utils.data.DataLoader(\n",
    "                      TestData(test_path, img_path, transform = val_test_transform),\n",
    "                      batch_size=32, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-28T04:03:23.681531Z",
     "iopub.status.idle": "2021-06-28T04:03:23.681939Z"
    },
    "id": "0l-USFxpOYty"
   },
   "outputs": [],
   "source": [
    "## predict\n",
    "model = resnest_model(176)\n",
    "\n",
    "# create model and load weights from checkpoint\n",
    "model = model.to(device)\n",
    "# load the all folds\n",
    "for test_fold in range(k_folds):\n",
    "  model_path = f'./model-fold-{test_fold}.pth'\n",
    "  saveFileName = f'./submission-fold-{test_fold}.csv'\n",
    "  model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "  # Make sure the model is in eval mode.\n",
    "  # Some modules like Dropout or BatchNorm affect if the model is in training mode.\n",
    "  model.eval()\n",
    "  tta_model = tta.ClassificationTTAWrapper(model, tta.aliases.five_crop_transform(200,200)) # Test-Time Augmentation\n",
    "\n",
    "  # Initialize a list to store the predictions.\n",
    "  predictions = []\n",
    "  # Iterate the testing set by batches.\n",
    "  for batch in tqdm(testloader):\n",
    "      \n",
    "      imgs = batch\n",
    "      with torch.no_grad():\n",
    "          logits = tta_model(imgs.to(device))\n",
    "      \n",
    "      # Take the class with greatest logit as prediction and record it.\n",
    "      predictions.extend(logits.argmax(dim=-1).cpu().numpy().tolist())\n",
    "\n",
    "  preds = []\n",
    "  for i in predictions:\n",
    "      preds.append(num_to_class[i])\n",
    "\n",
    "  test_data = pd.read_csv(test_path)\n",
    "  test_data['label'] = pd.Series(preds)\n",
    "  submission = pd.concat([test_data['image'], test_data['label']], axis=1)\n",
    "  submission.to_csv(saveFileName, index=False)\n",
    "  print(\"ResNeSt Model Results Done!!!!!!!!!!!!!!!!!!!!!!!!!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IjIr3i27APLP"
   },
   "source": [
    "### **ResNeSt的5折交叉验证的结果投票**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-28T04:03:23.682816Z",
     "iopub.status.idle": "2021-06-28T04:03:23.683228Z"
    },
    "id": "PKieA1DR7j1d"
   },
   "outputs": [],
   "source": [
    "# 读取5折交叉验证的结果\n",
    "df0 = pd.read_csv('./submission-fold-0.csv')\n",
    "df1 = pd.read_csv('./submission-fold-1.csv')\n",
    "df2 = pd.read_csv('./submission-fold-2.csv')\n",
    "df3 = pd.read_csv('./submission-fold-3.csv')\n",
    "df4 = pd.read_csv('./submission-fold-4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-28T04:03:23.684119Z",
     "iopub.status.idle": "2021-06-28T04:03:23.684561Z"
    },
    "id": "HukZ6ikN8ODD"
   },
   "outputs": [],
   "source": [
    "# 往第0折结果里添加数字化标签列\n",
    "list_num_label0 = []\n",
    "for i in df0['label']:\n",
    "  list_num_label0.append(class_to_num[i])\n",
    "df0['num_label0']=list_num_label0\n",
    "df0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-28T04:03:23.685348Z",
     "iopub.status.idle": "2021-06-28T04:03:23.685796Z"
    },
    "id": "fVisaaKR8Pfq"
   },
   "outputs": [],
   "source": [
    "# 往第1折结果里添加数字化标签列\n",
    "list_num_label1 = []\n",
    "for i in df1['label']:\n",
    "  list_num_label1.append(class_to_num[i])\n",
    "df1['num_label1']=list_num_label1\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-28T04:03:23.686639Z",
     "iopub.status.idle": "2021-06-28T04:03:23.687064Z"
    },
    "id": "lUtmlGbU9E0x"
   },
   "outputs": [],
   "source": [
    "# 往第2折结果里添加数字化标签列\n",
    "list_num_label2 = []\n",
    "for i in df2['label']:\n",
    "  list_num_label2.append(class_to_num[i])\n",
    "df2['num_label2']=list_num_label2\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-28T04:03:23.687907Z",
     "iopub.status.idle": "2021-06-28T04:03:23.688334Z"
    },
    "id": "Coqj8NMf9KJq"
   },
   "outputs": [],
   "source": [
    "# 往第3折结果里添加数字化标签列\n",
    "list_num_label3 = []\n",
    "for i in df3['label']:\n",
    "  list_num_label3.append(class_to_num[i])\n",
    "df3['num_label3']=list_num_label3\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-28T04:03:23.68924Z",
     "iopub.status.idle": "2021-06-28T04:03:23.689701Z"
    },
    "id": "htPczSqT9Pua"
   },
   "outputs": [],
   "source": [
    "# 往第4折结果里添加数字化标签列\n",
    "list_num_label4 = []\n",
    "for i in df4['label']:\n",
    "  list_num_label4.append(class_to_num[i])\n",
    "df4['num_label4']=list_num_label4\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-28T04:03:23.690722Z",
     "iopub.status.idle": "2021-06-28T04:03:23.691148Z"
    },
    "id": "pt_MGztN9UJq"
   },
   "outputs": [],
   "source": [
    "# 准备整合5折的结果到同一个DataFrame\n",
    "df_all = df0.copy()\n",
    "df_all.drop(['label'],axis=1,inplace=True)\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-28T04:03:23.692043Z",
     "iopub.status.idle": "2021-06-28T04:03:23.692482Z"
    },
    "id": "sOPq5bby-A76"
   },
   "outputs": [],
   "source": [
    "# 整合5折的数字化标签结果到同一个DataFrame\n",
    "df_all['num_label1']=list_num_label1\n",
    "df_all['num_label2']=list_num_label2\n",
    "df_all['num_label3']=list_num_label3\n",
    "df_all['num_label4']=list_num_label4\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-28T04:03:23.693289Z",
     "iopub.status.idle": "2021-06-28T04:03:23.693721Z"
    },
    "id": "aLcatNuh-QKa"
   },
   "outputs": [],
   "source": [
    "# 对df_all进行转置，方便求众数\n",
    "df_all_transpose = df_all.copy().drop(['image'],axis=1).transpose()\n",
    "df_all_transpose.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-28T04:03:23.694679Z",
     "iopub.status.idle": "2021-06-28T04:03:23.695118Z"
    },
    "id": "4uo7hDjJ-dP6"
   },
   "outputs": [],
   "source": [
    "# 求得投票众数\n",
    "df_mode = df_all_transpose.mode().transpose()\n",
    "df_mode.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-28T04:03:23.696006Z",
     "iopub.status.idle": "2021-06-28T04:03:23.696423Z"
    },
    "id": "o84YL1Sn-8qL"
   },
   "outputs": [],
   "source": [
    "# 把投票结果的数字化标签转成字符串标签\n",
    "voting_class = []\n",
    "for each in df_mode[0]:\n",
    "  voting_class.append(num_to_class[each])\n",
    "voting_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-28T04:03:23.697296Z",
     "iopub.status.idle": "2021-06-28T04:03:23.697727Z"
    },
    "id": "oU7E6R6H_nq4"
   },
   "outputs": [],
   "source": [
    "# 将投票结果的字符串标签添加到df_all中\n",
    "df_all['label'] = voting_class\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-28T04:03:23.698635Z",
     "iopub.status.idle": "2021-06-28T04:03:23.699058Z"
    },
    "id": "RBL_QsyY_1go"
   },
   "outputs": [],
   "source": [
    "# 提取image和label两列为最终的结果\n",
    "df_submission = df_all[['image','label']].copy()\n",
    "df_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-28T04:03:23.700112Z",
     "iopub.status.idle": "2021-06-28T04:03:23.700645Z"
    },
    "id": "LfhAzq4yAGSI"
   },
   "outputs": [],
   "source": [
    "# 保存当前模型得到的最终结果\n",
    "df_submission.to_csv('./submission-resnest.csv', index=False)\n",
    "print('Voting results of resnest successfully saved!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **基于ResNeXt模型部分**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nk1vuWbh-7Ry"
   },
   "source": [
    "### **ResNeXt模型**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-28T04:03:23.701525Z",
     "iopub.status.idle": "2021-06-28T04:03:23.701969Z"
    }
   },
   "outputs": [],
   "source": [
    "# 是否要冻住模型的前面一些层\n",
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        model = model\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "# resnext50_32x4d模型\n",
    "def resnext_model(num_classes, feature_extract = False, use_pretrained=True):\n",
    "\n",
    "    model_ft = models.resnext50_32x4d(pretrained=use_pretrained)\n",
    "    set_parameter_requires_grad(model_ft, feature_extract)\n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "    model_ft.fc = nn.Sequential(nn.Linear(num_ftrs, num_classes))\n",
    "\n",
    "    return model_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-28T04:03:23.702859Z",
     "iopub.status.idle": "2021-06-28T04:03:23.703278Z"
    }
   },
   "outputs": [],
   "source": [
    "# Configuration options\n",
    "k_folds = 5\n",
    "num_epochs = 30\n",
    "learning_rate = 1e-3\n",
    "weight_decay = 1e-3\n",
    "train_loss_function = CutMixCrossEntropyLoss(True)\n",
    "valid_loss_function = nn.CrossEntropyLoss()\n",
    "# For fold results\n",
    "results = {}\n",
    "\n",
    "# Set fixed random number seed\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=k_folds, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **训练**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-28T04:03:23.704534Z",
     "iopub.status.idle": "2021-06-28T04:03:23.704982Z"
    }
   },
   "outputs": [],
   "source": [
    "# Start print\n",
    "print('--------------------------------------')\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "for fold, (train_ids,valid_ids) in enumerate(kfold.split(train_val_dataset)):\n",
    "\n",
    "  # Print\n",
    "  print(f'FOLD {fold}')\n",
    "  print('--------------------------------------')\n",
    "\n",
    "  # Sample elements randomly from a given list of ids, no replacement.\n",
    "  train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "  valid_subsampler = torch.utils.data.SubsetRandomSampler(valid_ids)\n",
    "\n",
    "  # Define data loaders for training and testing data in this fold\n",
    "  trainloader = torch.utils.data.DataLoader(\n",
    "                      CutMix(TrainValidData(train_val_path, img_path, transform = train_transform), num_class=176, beta=1.0, prob=0.5, num_mix=2), \n",
    "                      batch_size=128, sampler=train_subsampler, num_workers=0)\n",
    "  validloader = torch.utils.data.DataLoader(\n",
    "                      TrainValidData(train_val_path, img_path, transform = val_test_transform),\n",
    "                      batch_size=128, sampler=valid_subsampler, num_workers=0)\n",
    "  \n",
    "  # Initialize a model and put it on the device specified.\n",
    "  model = resnext_model(176)\n",
    "  model = model.to(device)\n",
    "  model.device = device\n",
    "  \n",
    "  # Initialize optimizer\n",
    "  optimizer = torch.optim.AdamW(model.parameters(),lr=learning_rate,weight_decay= weight_decay)\n",
    "#   optimizer = SWA(our_optimizer, swa_start=5, swa_freq =5, swa_lr=0.05)\n",
    "  scheduler = CosineAnnealingLR(optimizer,T_max=10)\n",
    "\n",
    "  # Run the training loop for defined number of epochs\n",
    "  for epoch in range(0,num_epochs):\n",
    "    model.train()\n",
    "    # Print epoch\n",
    "    print(f'Starting epoch {epoch+1}')\n",
    "    # These are used to record information in training\n",
    "    train_losses = []\n",
    "    train_accs = []\n",
    "    # Iterate the training set by batches\n",
    "    for batch in tqdm(trainloader):\n",
    "      # Move images and labels to GPU\n",
    "      imgs, labels = batch\n",
    "      imgs = imgs.to(device)\n",
    "      labels = labels.to(device)\n",
    "      # Forward the data\n",
    "      logits = model(imgs)\n",
    "      # Calculate loss\n",
    "      loss = train_loss_function(logits,labels)\n",
    "      # Clear gradients in previous step\n",
    "      optimizer.zero_grad()\n",
    "      # Compute gradients for parameters\n",
    "      loss.backward()\n",
    "      # Update the parameters with computed gradients\n",
    "      optimizer.step()\n",
    "      # Compute the accuracy for current batch.\n",
    "      # acc = (logits.argmax(dim=-1) == labels).float().mean()\n",
    "      # Record the loss and accuracy.\n",
    "      train_losses.append(loss.item())\n",
    "      # train_accs.append(acc)\n",
    "    print(\"第%d个epoch的学习率：%f\" % (epoch+1,optimizer.param_groups[0]['lr']))\n",
    "    scheduler.step()\n",
    "    # The average loss and accuracy of the training set is the average of the recorded values.\n",
    "    train_loss = np.sum(train_losses) / len(train_losses)\n",
    "    # train_acc = np.sum(train_accs) / len(train_accs)\n",
    "    # Print the information.\n",
    "    # print(f\"[ Train | {epoch + 1:03d}/{num_epochs:03d} ] loss = {train_loss:.5f}, acc = {train_acc:.5f}\")\n",
    "    print(f\"[ Train | {epoch + 1:03d}/{num_epochs:03d} ] loss = {train_loss:.5f}\")\n",
    "\n",
    "  # Train process (all epochs) is complete\n",
    "  print('Training process has finished. Saving trained model.')\n",
    "  print('Starting validation')\n",
    "\n",
    "  # Saving the model\n",
    "  print('saving model with loss {:.3f}'.format(train_loss))\n",
    "  save_path = f'./model-fold-{fold}.pth'\n",
    "  torch.save(model.state_dict(),save_path)\n",
    "  # Start Validation\n",
    "  model.eval()\n",
    "  valid_losses = []\n",
    "  valid_accs = []\n",
    "  with torch.no_grad():\n",
    "    for batch in tqdm(validloader):\n",
    "      imgs, labels = batch\n",
    "      # No gradient in validation\n",
    "      logits = model(imgs.to(device))\n",
    "      loss = valid_loss_function(logits,labels.to(device))\n",
    "      acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n",
    "      # Record loss and accuracy\n",
    "      valid_losses.append(loss.item())        \n",
    "      valid_accs.append(acc)\n",
    "    # The average loss and accuracy\n",
    "    valid_loss = np.sum(valid_losses)/len(valid_losses)\n",
    "    valid_acc = np.sum(valid_accs)/len(valid_accs)\n",
    "    print(f\"[ Valid | {epoch + 1:03d}/{num_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}\")\n",
    "    print('Accuracy for fold %d: %d' % (fold, valid_acc))\n",
    "    print('--------------------------------------')\n",
    "    results[fold] = valid_acc\n",
    "# Print fold results\n",
    "print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n",
    "print('--------------------------------')\n",
    "total_summation = 0.0\n",
    "for key, value in results.items():\n",
    "  print(f'Fold {key}: {value} ')\n",
    "  total_summation += value\n",
    "print(f'Average: {total_summation/len(results.items())} ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **预测**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-28T04:03:23.70594Z",
     "iopub.status.idle": "2021-06-28T04:03:23.706365Z"
    }
   },
   "outputs": [],
   "source": [
    "testloader = torch.utils.data.DataLoader(\n",
    "                      TestData(test_path, img_path, transform = val_test_transform),\n",
    "                      batch_size=128, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-28T04:03:23.707306Z",
     "iopub.status.idle": "2021-06-28T04:03:23.707748Z"
    }
   },
   "outputs": [],
   "source": [
    "## predict\n",
    "model = resnext_model(176)\n",
    "\n",
    "# create model and load weights from checkpoint\n",
    "model = model.to(device)\n",
    "# load the all folds\n",
    "for test_fold in range(k_folds):\n",
    "  model_path = f'./model-fold-{test_fold}.pth'\n",
    "  saveFileName = f'./submission-fold-{test_fold}.csv'\n",
    "  model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "  # Make sure the model is in eval mode.\n",
    "  # Some modules like Dropout or BatchNorm affect if the model is in training mode.\n",
    "  model.eval()\n",
    "  tta_model = tta.ClassificationTTAWrapper(model, tta.aliases.five_crop_transform(200,200))\n",
    "\n",
    "  # Initialize a list to store the predictions.\n",
    "  predictions = []\n",
    "  # Iterate the testing set by batches.\n",
    "  for batch in tqdm(testloader):\n",
    "      \n",
    "      imgs = batch\n",
    "      with torch.no_grad():\n",
    "          logits = tta_model(imgs.to(device))\n",
    "      \n",
    "      # Take the class with greatest logit as prediction and record it.\n",
    "      predictions.extend(logits.argmax(dim=-1).cpu().numpy().tolist())\n",
    "\n",
    "  preds = []\n",
    "  for i in predictions:\n",
    "      preds.append(num_to_class[i])\n",
    "\n",
    "  test_data = pd.read_csv(test_path)\n",
    "  test_data['label'] = pd.Series(preds)\n",
    "  submission = pd.concat([test_data['image'], test_data['label']], axis=1)\n",
    "  submission.to_csv(saveFileName, index=False)\n",
    "  print(\"ResNeXt Model Results Done!!!!!!!!!!!!!!!!!!!!!!!!!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **ResNeXt的5折交叉验证的结果投票**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-28T04:03:23.70882Z",
     "iopub.status.idle": "2021-06-28T04:03:23.709244Z"
    }
   },
   "outputs": [],
   "source": [
    "df0 = pd.read_csv('./submission-fold-0.csv')\n",
    "df1 = pd.read_csv('./submission-fold-1.csv')\n",
    "df2 = pd.read_csv('./submission-fold-2.csv')\n",
    "df3 = pd.read_csv('./submission-fold-3.csv')\n",
    "df4 = pd.read_csv('./submission-fold-4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-28T04:03:23.710194Z",
     "iopub.status.idle": "2021-06-28T04:03:23.71064Z"
    }
   },
   "outputs": [],
   "source": [
    "list_num_label0 = []\n",
    "for i in df0['label']:\n",
    "  list_num_label0.append(class_to_num[i])\n",
    "df0['num_label0']=list_num_label0\n",
    "df0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-28T04:03:23.711472Z",
     "iopub.status.idle": "2021-06-28T04:03:23.711902Z"
    }
   },
   "outputs": [],
   "source": [
    "list_num_label1 = []\n",
    "for i in df1['label']:\n",
    "  list_num_label1.append(class_to_num[i])\n",
    "df1['num_label1']=list_num_label1\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-28T04:03:23.712976Z",
     "iopub.status.idle": "2021-06-28T04:03:23.713435Z"
    }
   },
   "outputs": [],
   "source": [
    "list_num_label2 = []\n",
    "for i in df2['label']:\n",
    "  list_num_label2.append(class_to_num[i])\n",
    "df2['num_label2']=list_num_label2\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-28T04:03:23.714354Z",
     "iopub.status.idle": "2021-06-28T04:03:23.714793Z"
    }
   },
   "outputs": [],
   "source": [
    "list_num_label3 = []\n",
    "for i in df3['label']:\n",
    "  list_num_label3.append(class_to_num[i])\n",
    "df3['num_label3']=list_num_label3\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-28T04:03:23.715627Z",
     "iopub.status.idle": "2021-06-28T04:03:23.716073Z"
    }
   },
   "outputs": [],
   "source": [
    "list_num_label4 = []\n",
    "for i in df4['label']:\n",
    "  list_num_label4.append(class_to_num[i])\n",
    "df4['num_label4']=list_num_label4\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-28T04:03:23.717018Z",
     "iopub.status.idle": "2021-06-28T04:03:23.717445Z"
    }
   },
   "outputs": [],
   "source": [
    "df_all = df0.copy()\n",
    "df_all.drop(['label'],axis=1,inplace=True)\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-28T04:03:23.718335Z",
     "iopub.status.idle": "2021-06-28T04:03:23.718781Z"
    }
   },
   "outputs": [],
   "source": [
    "df_all['num_label1']=list_num_label1\n",
    "df_all['num_label2']=list_num_label2\n",
    "df_all['num_label3']=list_num_label3\n",
    "df_all['num_label4']=list_num_label4\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-28T04:03:23.719616Z",
     "iopub.status.idle": "2021-06-28T04:03:23.720043Z"
    }
   },
   "outputs": [],
   "source": [
    "df_all_transpose = df_all.copy().drop(['image'],axis=1).transpose()\n",
    "df_all_transpose.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-28T04:03:23.721088Z",
     "iopub.status.idle": "2021-06-28T04:03:23.72152Z"
    }
   },
   "outputs": [],
   "source": [
    "df_mode = df_all_transpose.mode().transpose()\n",
    "df_mode.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-28T04:03:23.722314Z",
     "iopub.status.idle": "2021-06-28T04:03:23.722732Z"
    }
   },
   "outputs": [],
   "source": [
    "voting_class = []\n",
    "for each in df_mode[0]:\n",
    "  voting_class.append(num_to_class[each])\n",
    "voting_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-28T04:03:23.723674Z",
     "iopub.status.idle": "2021-06-28T04:03:23.724087Z"
    }
   },
   "outputs": [],
   "source": [
    "df_all['label'] = voting_class\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-28T04:03:23.725061Z",
     "iopub.status.idle": "2021-06-28T04:03:23.72551Z"
    }
   },
   "outputs": [],
   "source": [
    "df_submission = df_all[['image','label']].copy()\n",
    "df_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-28T04:03:23.726404Z",
     "iopub.status.idle": "2021-06-28T04:03:23.72684Z"
    }
   },
   "outputs": [],
   "source": [
    "df_submission.to_csv('./submission-resnext.csv', index=False)\n",
    "print('ResNeXt voting results successfully saved!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **基于DenseNet模型部分**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **DenseNet模型**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-28T04:03:23.727889Z",
     "iopub.status.idle": "2021-06-28T04:03:23.728325Z"
    }
   },
   "outputs": [],
   "source": [
    "# 是否要冻住模型的前面一些层\n",
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        model = model\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "# densenet161模型\n",
    "def dense_model(num_classes, feature_extract = False, use_pretrained=True):\n",
    "\n",
    "    model_ft = models.densenet161(pretrained=use_pretrained)\n",
    "    set_parameter_requires_grad(model_ft, feature_extract)\n",
    "    num_ftrs = model_ft.classifier.in_features\n",
    "    model_ft.classifier = nn.Sequential(nn.Linear(num_ftrs, num_classes))\n",
    "\n",
    "    return model_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-28T04:03:23.729239Z",
     "iopub.status.idle": "2021-06-28T04:03:23.729685Z"
    }
   },
   "outputs": [],
   "source": [
    "# Configuration options\n",
    "k_folds = 5\n",
    "num_epochs = 30\n",
    "learning_rate = 1e-4\n",
    "weight_decay = 1e-3\n",
    "train_loss_function = CutMixCrossEntropyLoss(True)\n",
    "valid_loss_function = nn.CrossEntropyLoss()\n",
    "# For fold results\n",
    "results = {}\n",
    "\n",
    "# Set fixed random number seed\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=k_folds, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **训练**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-28T04:03:23.730947Z",
     "iopub.status.idle": "2021-06-28T04:03:23.731377Z"
    }
   },
   "outputs": [],
   "source": [
    "# Start print\n",
    "print('--------------------------------------')\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "for fold, (train_ids,valid_ids) in enumerate(kfold.split(train_val_dataset)):\n",
    "\n",
    "  # Print\n",
    "  print(f'FOLD {fold}')\n",
    "  print('--------------------------------------')\n",
    "\n",
    "  # Sample elements randomly from a given list of ids, no replacement.\n",
    "  train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "  valid_subsampler = torch.utils.data.SubsetRandomSampler(valid_ids)\n",
    "\n",
    "  # Define data loaders for training and testing data in this fold\n",
    "  trainloader = torch.utils.data.DataLoader(\n",
    "                      CutMix(TrainValidData(train_val_path, img_path, transform = train_transform), num_class=176, beta=1.0, prob=0.5, num_mix=2), \n",
    "                      batch_size=32, sampler=train_subsampler, num_workers=0)\n",
    "  validloader = torch.utils.data.DataLoader(\n",
    "                      TrainValidData(train_val_path, img_path, transform = val_test_transform),\n",
    "                      batch_size=32, sampler=valid_subsampler, num_workers=0)\n",
    "  \n",
    "  # Initialize a model and put it on the device specified.\n",
    "  model = dense_model(176)\n",
    "  model = model.to(device)\n",
    "  model.device = device\n",
    "  \n",
    "  # Initialize optimizer\n",
    "  optimizer = torch.optim.AdamW(model.parameters(),lr=learning_rate,weight_decay= weight_decay)\n",
    "  scheduler = CosineAnnealingLR(optimizer,T_max=10)\n",
    "\n",
    "  # Run the training loop for defined number of epochs\n",
    "  for epoch in range(0,num_epochs):\n",
    "    model.train()\n",
    "    # Print epoch\n",
    "    print(f'Starting epoch {epoch+1}')\n",
    "    # These are used to record information in training\n",
    "    train_losses = []\n",
    "    train_accs = []\n",
    "    # Iterate the training set by batches\n",
    "    for batch in tqdm(trainloader):\n",
    "      # Move images and labels to GPU\n",
    "      imgs, labels = batch\n",
    "      imgs = imgs.to(device)\n",
    "      labels = labels.to(device)\n",
    "      # Forward the data\n",
    "      logits = model(imgs)\n",
    "      # Calculate loss\n",
    "      loss = train_loss_function(logits,labels)\n",
    "      # Clear gradients in previous step\n",
    "      optimizer.zero_grad()\n",
    "      # Compute gradients for parameters\n",
    "      loss.backward()\n",
    "      # Update the parameters with computed gradients\n",
    "      optimizer.step()\n",
    "      # Compute the accuracy for current batch.\n",
    "#       acc = (logits.argmax(dim=-1) == labels).float().mean()\n",
    "      # Record the loss and accuracy.\n",
    "      train_losses.append(loss.item())\n",
    "#       train_accs.append(acc)\n",
    "    print(\"第%d个epoch的学习率：%f\" % (epoch+1,optimizer.param_groups[0]['lr']))\n",
    "    scheduler.step()\n",
    "    # The average loss and accuracy of the training set is the average of the recorded values.\n",
    "    train_loss = np.sum(train_losses) / len(train_losses)\n",
    "#     train_acc = np.sum(train_accs) / len(train_accs)\n",
    "    # Print the information.\n",
    "#     print(f\"[ Train | {epoch + 1:03d}/{num_epochs:03d} ] loss = {train_loss:.5f}, acc = {train_acc:.5f}\")\n",
    "    print(f\"[ Train | {epoch + 1:03d}/{num_epochs:03d} ] loss = {train_loss:.5f}\")\n",
    "\n",
    "  # Train process (all epochs) is complete\n",
    "  print('Training process has finished. Saving trained model.')\n",
    "  print('Starting validation')\n",
    "\n",
    "  # Saving the model\n",
    "  print('saving model with loss {:.3f}'.format(train_loss))\n",
    "  save_path = f'./model-fold-{fold}.pth'\n",
    "  torch.save(model.state_dict(),save_path)\n",
    "  # Start Validation\n",
    "  model.eval()\n",
    "  valid_losses = []\n",
    "  valid_accs = []\n",
    "  with torch.no_grad():\n",
    "    for batch in tqdm(validloader):\n",
    "      imgs, labels = batch\n",
    "      # No gradient in validation\n",
    "      logits = model(imgs.to(device))\n",
    "      loss = valid_loss_function(logits,labels.to(device))\n",
    "      acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n",
    "      # Record loss and accuracy\n",
    "      valid_losses.append(loss.item())        \n",
    "      valid_accs.append(acc)\n",
    "    # The average loss and accuracy\n",
    "    valid_loss = np.sum(valid_losses)/len(valid_losses)\n",
    "    valid_acc = np.sum(valid_accs)/len(valid_accs)\n",
    "    print(f\"[ Valid | {epoch + 1:03d}/{num_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}\")\n",
    "    print('Accuracy for fold %d: %d' % (fold, valid_acc))\n",
    "    print('--------------------------------------')\n",
    "    results[fold] = valid_acc\n",
    "# Print fold results\n",
    "print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n",
    "print('--------------------------------')\n",
    "total_summation = 0.0\n",
    "for key, value in results.items():\n",
    "  print(f'Fold {key}: {value} ')\n",
    "  total_summation += value\n",
    "print(f'Average: {total_summation/len(results.items())} ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **预测**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-28T04:03:23.732239Z",
     "iopub.status.idle": "2021-06-28T04:03:23.732679Z"
    }
   },
   "outputs": [],
   "source": [
    "testloader = torch.utils.data.DataLoader(\n",
    "                      TestData(test_path, img_path, transform = val_test_transform),\n",
    "                      batch_size=32, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-28T04:03:23.733527Z",
     "iopub.status.idle": "2021-06-28T04:03:23.733952Z"
    }
   },
   "outputs": [],
   "source": [
    "## predict\n",
    "model = dense_model(176)\n",
    "\n",
    "# create model and load weights from checkpoint\n",
    "model = model.to(device)\n",
    "# load the all folds\n",
    "for test_fold in range(k_folds):\n",
    "  model_path = f'./model-fold-{test_fold}.pth'\n",
    "  saveFileName = f'./submission-fold-{test_fold}.csv'\n",
    "  model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "  # Make sure the model is in eval mode.\n",
    "  # Some modules like Dropout or BatchNorm affect if the model is in training mode.\n",
    "  model.eval()\n",
    "  tta_model = tta.ClassificationTTAWrapper(model, tta.aliases.five_crop_transform(200,200))\n",
    "\n",
    "  # Initialize a list to store the predictions.\n",
    "  predictions = []\n",
    "  # Iterate the testing set by batches.\n",
    "  for batch in tqdm(testloader):\n",
    "      \n",
    "      imgs = batch\n",
    "      with torch.no_grad():\n",
    "          logits = tta_model(imgs.to(device))\n",
    "      \n",
    "      # Take the class with greatest logit as prediction and record it.\n",
    "      predictions.extend(logits.argmax(dim=-1).cpu().numpy().tolist())\n",
    "\n",
    "  preds = []\n",
    "  for i in predictions:\n",
    "      preds.append(num_to_class[i])\n",
    "\n",
    "  test_data = pd.read_csv(test_path)\n",
    "  test_data['label'] = pd.Series(preds)\n",
    "  submission = pd.concat([test_data['image'], test_data['label']], axis=1)\n",
    "  submission.to_csv(saveFileName, index=False)\n",
    "  print(\"Dense Model Results Done!!!!!!!!!!!!!!!!!!!!!!!!!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **DenseNet的5折交叉验证的结果投票**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-28T04:03:23.734843Z",
     "iopub.status.idle": "2021-06-28T04:03:23.735287Z"
    }
   },
   "outputs": [],
   "source": [
    "df0 = pd.read_csv('./submission-fold-0.csv')\n",
    "df1 = pd.read_csv('./submission-fold-1.csv')\n",
    "df2 = pd.read_csv('./submission-fold-2.csv')\n",
    "df3 = pd.read_csv('./submission-fold-3.csv')\n",
    "df4 = pd.read_csv('./submission-fold-4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-28T04:03:23.736175Z",
     "iopub.status.idle": "2021-06-28T04:03:23.73661Z"
    }
   },
   "outputs": [],
   "source": [
    "list_num_label0 = []\n",
    "for i in df0['label']:\n",
    "  list_num_label0.append(class_to_num[i])\n",
    "df0['num_label0']=list_num_label0\n",
    "df0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-28T04:03:23.737544Z",
     "iopub.status.idle": "2021-06-28T04:03:23.73797Z"
    }
   },
   "outputs": [],
   "source": [
    "list_num_label1 = []\n",
    "for i in df1['label']:\n",
    "  list_num_label1.append(class_to_num[i])\n",
    "df1['num_label1']=list_num_label1\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-28T04:03:23.738824Z",
     "iopub.status.idle": "2021-06-28T04:03:23.739257Z"
    }
   },
   "outputs": [],
   "source": [
    "list_num_label2 = []\n",
    "for i in df2['label']:\n",
    "  list_num_label2.append(class_to_num[i])\n",
    "df2['num_label2']=list_num_label2\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-28T04:03:23.740182Z",
     "iopub.status.idle": "2021-06-28T04:03:23.740626Z"
    }
   },
   "outputs": [],
   "source": [
    "list_num_label3 = []\n",
    "for i in df3['label']:\n",
    "  list_num_label3.append(class_to_num[i])\n",
    "df3['num_label3']=list_num_label3\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-28T04:03:23.741603Z",
     "iopub.status.idle": "2021-06-28T04:03:23.742039Z"
    }
   },
   "outputs": [],
   "source": [
    "list_num_label4 = []\n",
    "for i in df4['label']:\n",
    "  list_num_label4.append(class_to_num[i])\n",
    "df4['num_label4']=list_num_label4\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-28T04:03:23.742948Z",
     "iopub.status.idle": "2021-06-28T04:03:23.743388Z"
    }
   },
   "outputs": [],
   "source": [
    "df_all = df0.copy()\n",
    "df_all.drop(['label'],axis=1,inplace=True)\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-28T04:03:23.744319Z",
     "iopub.status.idle": "2021-06-28T04:03:23.744771Z"
    }
   },
   "outputs": [],
   "source": [
    "df_all['num_label1']=list_num_label1\n",
    "df_all['num_label2']=list_num_label2\n",
    "df_all['num_label3']=list_num_label3\n",
    "df_all['num_label4']=list_num_label4\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-28T04:03:23.745659Z",
     "iopub.status.idle": "2021-06-28T04:03:23.746088Z"
    }
   },
   "outputs": [],
   "source": [
    "df_all_transpose = df_all.copy().drop(['image'],axis=1).transpose()\n",
    "df_all_transpose.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-28T04:03:23.74706Z",
     "iopub.status.idle": "2021-06-28T04:03:23.747458Z"
    }
   },
   "outputs": [],
   "source": [
    "df_mode = df_all_transpose.mode().transpose()\n",
    "df_mode.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-28T04:03:23.748325Z",
     "iopub.status.idle": "2021-06-28T04:03:23.748741Z"
    }
   },
   "outputs": [],
   "source": [
    "voting_class = []\n",
    "for each in df_mode[0]:\n",
    "  voting_class.append(num_to_class[each])\n",
    "voting_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-28T04:03:23.749734Z",
     "iopub.status.idle": "2021-06-28T04:03:23.750197Z"
    }
   },
   "outputs": [],
   "source": [
    "df_all['label'] = voting_class\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-28T04:03:23.751176Z",
     "iopub.status.idle": "2021-06-28T04:03:23.751607Z"
    }
   },
   "outputs": [],
   "source": [
    "df_submission = df_all[['image','label']].copy()\n",
    "df_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-28T04:03:23.752542Z",
     "iopub.status.idle": "2021-06-28T04:03:23.752961Z"
    }
   },
   "outputs": [],
   "source": [
    "df_submission.to_csv('./submission-densenet.csv', index=False)\n",
    "print('Densenet results successfully saved!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **最终结果集成（投票方式）**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-28T04:13:53.154162Z",
     "iopub.status.busy": "2021-06-28T04:13:53.153683Z",
     "iopub.status.idle": "2021-06-28T04:13:53.213985Z",
     "shell.execute_reply": "2021-06-28T04:13:53.212754Z",
     "shell.execute_reply.started": "2021-06-28T04:13:53.154127Z"
    }
   },
   "outputs": [],
   "source": [
    "df_resnest = pd.read_csv('../input/classify-leaves-results/submission-resnest.csv')\n",
    "df_resnext = pd.read_csv('../input/classify-leaves-results/submission-resnext.csv')\n",
    "df_densenet = pd.read_csv('../input/classify-leaves-results/submission-densenet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-28T04:13:55.512599Z",
     "iopub.status.busy": "2021-06-28T04:13:55.512212Z",
     "iopub.status.idle": "2021-06-28T04:13:55.529233Z",
     "shell.execute_reply": "2021-06-28T04:13:55.528516Z",
     "shell.execute_reply.started": "2021-06-28T04:13:55.512565Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label_resnest</th>\n",
       "      <th>label_resnext</th>\n",
       "      <th>label_densenet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>images/18353.jpg</td>\n",
       "      <td>asimina_triloba</td>\n",
       "      <td>asimina_triloba</td>\n",
       "      <td>asimina_triloba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>images/18354.jpg</td>\n",
       "      <td>betula_nigra</td>\n",
       "      <td>betula_nigra</td>\n",
       "      <td>betula_nigra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>images/18355.jpg</td>\n",
       "      <td>platanus_acerifolia</td>\n",
       "      <td>platanus_acerifolia</td>\n",
       "      <td>platanus_acerifolia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>images/18356.jpg</td>\n",
       "      <td>pinus_bungeana</td>\n",
       "      <td>pinus_bungeana</td>\n",
       "      <td>pinus_bungeana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>images/18357.jpg</td>\n",
       "      <td>platanus_acerifolia</td>\n",
       "      <td>platanus_acerifolia</td>\n",
       "      <td>platanus_acerifolia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              image        label_resnest        label_resnext  \\\n",
       "0  images/18353.jpg      asimina_triloba      asimina_triloba   \n",
       "1  images/18354.jpg         betula_nigra         betula_nigra   \n",
       "2  images/18355.jpg  platanus_acerifolia  platanus_acerifolia   \n",
       "3  images/18356.jpg       pinus_bungeana       pinus_bungeana   \n",
       "4  images/18357.jpg  platanus_acerifolia  platanus_acerifolia   \n",
       "\n",
       "        label_densenet  \n",
       "0      asimina_triloba  \n",
       "1         betula_nigra  \n",
       "2  platanus_acerifolia  \n",
       "3       pinus_bungeana  \n",
       "4  platanus_acerifolia  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all = df_resnest.copy()\n",
    "df_all.rename(columns = {'label':'label_resnest'},inplace=True)\n",
    "df_all['label_resnext'] = df_resnext.copy()['label']\n",
    "df_all['label_densenet'] = df_densenet.copy()['label']\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-28T04:13:59.039433Z",
     "iopub.status.busy": "2021-06-28T04:13:59.038907Z",
     "iopub.status.idle": "2021-06-28T04:14:08.864030Z",
     "shell.execute_reply": "2021-06-28T04:14:08.862979Z",
     "shell.execute_reply.started": "2021-06-28T04:13:59.039400Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label_resnest</th>\n",
       "      <th>label_resnext</th>\n",
       "      <th>label_densenet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>images/18353.jpg</td>\n",
       "      <td>asimina_triloba</td>\n",
       "      <td>asimina_triloba</td>\n",
       "      <td>asimina_triloba</td>\n",
       "      <td>asimina_triloba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>images/18354.jpg</td>\n",
       "      <td>betula_nigra</td>\n",
       "      <td>betula_nigra</td>\n",
       "      <td>betula_nigra</td>\n",
       "      <td>betula_nigra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>images/18355.jpg</td>\n",
       "      <td>platanus_acerifolia</td>\n",
       "      <td>platanus_acerifolia</td>\n",
       "      <td>platanus_acerifolia</td>\n",
       "      <td>platanus_acerifolia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>images/18356.jpg</td>\n",
       "      <td>pinus_bungeana</td>\n",
       "      <td>pinus_bungeana</td>\n",
       "      <td>pinus_bungeana</td>\n",
       "      <td>pinus_bungeana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>images/18357.jpg</td>\n",
       "      <td>platanus_acerifolia</td>\n",
       "      <td>platanus_acerifolia</td>\n",
       "      <td>platanus_acerifolia</td>\n",
       "      <td>platanus_acerifolia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              image        label_resnest        label_resnext  \\\n",
       "0  images/18353.jpg      asimina_triloba      asimina_triloba   \n",
       "1  images/18354.jpg         betula_nigra         betula_nigra   \n",
       "2  images/18355.jpg  platanus_acerifolia  platanus_acerifolia   \n",
       "3  images/18356.jpg       pinus_bungeana       pinus_bungeana   \n",
       "4  images/18357.jpg  platanus_acerifolia  platanus_acerifolia   \n",
       "\n",
       "        label_densenet                label  \n",
       "0      asimina_triloba      asimina_triloba  \n",
       "1         betula_nigra         betula_nigra  \n",
       "2  platanus_acerifolia  platanus_acerifolia  \n",
       "3       pinus_bungeana       pinus_bungeana  \n",
       "4  platanus_acerifolia  platanus_acerifolia  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all['label']=0\n",
    "for rows in range(len(df_all)):\n",
    "    if (df_all['label_resnest'].iloc[rows]==df_all['label_resnext'].iloc[rows]) or (df_all['label_resnest'].iloc[rows]==df_all['label_densenet'].iloc[rows]):\n",
    "        df_all['label'].iloc[rows] = df_all.copy()['label_resnest'].iloc[rows]\n",
    "    elif df_all['label_resnext'].iloc[rows]==df_all['label_densenet'].iloc[rows]:\n",
    "        df_all['label'].iloc[rows] = df_all.copy()['label_resnext'].iloc[rows]\n",
    "    else:\n",
    "        df_all['label'].iloc[rows] = df_all.copy()['label_resnest'].iloc[rows]\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-28T04:14:13.241434Z",
     "iopub.status.busy": "2021-06-28T04:14:13.240869Z",
     "iopub.status.idle": "2021-06-28T04:14:13.256092Z",
     "shell.execute_reply": "2021-06-28T04:14:13.254427Z",
     "shell.execute_reply.started": "2021-06-28T04:14:13.241384Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>images/18353.jpg</td>\n",
       "      <td>asimina_triloba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>images/18354.jpg</td>\n",
       "      <td>betula_nigra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>images/18355.jpg</td>\n",
       "      <td>platanus_acerifolia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>images/18356.jpg</td>\n",
       "      <td>pinus_bungeana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>images/18357.jpg</td>\n",
       "      <td>platanus_acerifolia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              image                label\n",
       "0  images/18353.jpg      asimina_triloba\n",
       "1  images/18354.jpg         betula_nigra\n",
       "2  images/18355.jpg  platanus_acerifolia\n",
       "3  images/18356.jpg       pinus_bungeana\n",
       "4  images/18357.jpg  platanus_acerifolia"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final = df_all.copy()[['image','label']]\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-28T04:14:17.970960Z",
     "iopub.status.busy": "2021-06-28T04:14:17.970596Z",
     "iopub.status.idle": "2021-06-28T04:14:18.005325Z",
     "shell.execute_reply": "2021-06-28T04:14:18.004214Z",
     "shell.execute_reply.started": "2021-06-28T04:14:17.970929Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final results successfully saved!\n"
     ]
    }
   ],
   "source": [
    "df_final.to_csv('./submission.csv', index=False)\n",
    "print('Final results successfully saved!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
